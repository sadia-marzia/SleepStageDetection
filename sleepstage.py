# -*- coding: utf-8 -*-
"""Sleepstage.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PT0txKlPBBJZe0UaBrot8M2wj7FClKSD
"""

!pip install mne pandas numpy

!pip install pyedflib

from google.colab import files

def load_respevt_file(event_file):
    events = []
    with open(event_file, 'r') as f:
        # Skip header lines
        lines = f.readlines()[1:]

        for line in lines:
            parts = line.strip().split()
            if len(parts) > 1 and parts[0] != "Respiratory":  # Skip non-relevant lines
                try:
                    event_time = parts[0]  # event start time (HH:MM:SS)
                    event_type = parts[1]  # apnea type (HYP, C, O, M)
                    # Add event to list if valid
                    events.append((event_time, event_type))
                except ValueError:
                    # Handle any malformed lines or unexpected content
                    continue
    return events

# Load the data
events = load_respevt_file('/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb002_respevt.txt')

# Display first few events to check the output
print("First few events:", events[:5])

def load_sleep_stages(stage_file):
    stages = []
    with open(stage_file, 'r') as f:
        for line in f:
            stages.append(int(line.strip()))
    return stages

# Load the sleep stages from the stage.txt file
sleep_stages = load_sleep_stages('/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb002_stage.txt')

# Print first few stages to inspect
print(sleep_stages[:50])  # Inspect first 50 stages

"""# **.rec file info check**"""

import pyedflib

def display_edf_contents(file_path):
    try:
        # Open the EDF file
        edf_file = pyedflib.EdfReader(file_path)

        # Display basic information about the EDF file
        print(f"Number of signals: {edf_file.signals_in_file}")
        print(f"Signal labels: {edf_file.getSignalLabels()}")
        print(f"Sample frequency of the first signal: {edf_file.getSampleFrequency(0)}")

        # Read data from the first signal (e.g., EEG)
        signal_data = edf_file.readSignal(0)  # Read the first signal
        print(f"First 100 samples of the first signal: {signal_data[:100]}")

        # Close the file
        edf_file._close()
    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage
file_path = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb002.rec'  # Replace with your actual file path
display_edf_contents(file_path)

import matplotlib.pyplot as plt
import pandas as pd
import os
import numpy as np

def plot_signal(edf_file, signal_index=5, num_samples=500):
    signal_data = edf_file.readSignal(signal_index)  # Read signal at the specified index
    time = np.arange(num_samples) / edf_file.getSampleFrequency(signal_index)  # Time axis for the signal

    # Plot the first 'num_samples' data points of the signal
    plt.plot(time[:num_samples], signal_data[:num_samples])
    plt.title(f"Signal {signal_index}: {edf_file.getSignalLabels()[signal_index]}")
    plt.xlabel('Time (s)')
    plt.ylabel('Amplitude')
    plt.show()

# Example usage
file_path = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb002.rec'
edf_file = pyedflib.EdfReader(file_path)
plot_signal(edf_file, signal_index=5, num_samples=500)  # Example: Plotting the 6th signal (ECG)
edf_file._close()

"""# **.edf file length check**"""

import pyedflib

def calculate_signal_length(file_path, signal_index=0):
    try:
        # Open the EDF file
        edf_file = pyedflib.EdfReader(file_path)

        # Get the total number of samples for the specified signal
        num_samples = edf_file.getNSamples()[signal_index]

        # Get the sampling frequency (Hz) for the specified signal
        sample_frequency = edf_file.getSampleFrequency(signal_index)

        # Calculate the signal length in seconds
        signal_length_seconds = num_samples / sample_frequency

        # Convert the length to minutes
        signal_length_minutes = signal_length_seconds / 30

        print(f"Signal {signal_index} length:")
        print(f"  - {signal_length_seconds:.2f} seconds")
        print(f"  - {signal_length_minutes:.2f} minutes")

        # Close the EDF file
        edf_file._close()
        return signal_length_seconds, signal_length_minutes
    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage
file_path = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb002.rec'  # Replace with your actual file path
calculate_signal_length(file_path, signal_index=0)  # Example: Calculating for the first signal

def count_lines_in_file(file_path):
    with open(file_path, 'r') as file:
        lines = file.readlines()
        print(f"Total number of lines in the file: {len(lines)}")
        return len(lines)

# Example usage
file_path = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb002_stage.txt'  # Replace with your actual file path
count_lines_in_file(file_path)

"""# **Segmenting the .rec files which contains 14 types of signals and being saved into .csv file with resampled to 128Hz**"""

import pyedflib
import numpy as np
import os
import pandas as pd
from scipy.signal import resample

# Function to resample signals to the target frequency (128 Hz)
def resample_signal(signal, original_fs, target_fs=128):
    # Calculate the number of samples required for the target frequency
    target_samples = int(len(signal) * target_fs / original_fs)
    # Resample the signal using scipy's resample function
    resampled_signal = resample(signal, target_samples)
    return resampled_signal

# Function to resample the signals and save them to a new folder
def resample_signals(file_path, output_folder, target_fs=128, segment_duration=30):
    try:
        # Open the EDF file
        edf_file = pyedflib.EdfReader(file_path)

        # Get basic information from the file
        signal_labels = edf_file.getSignalLabels()
        fs_list = edf_file.getSampleFrequencies()  # List of sampling frequencies for each signal
        num_samples_list = edf_file.getNSamples()  # Number of samples for each signal

        # Calculate the number of segments based on the first signal (assuming all signals have the same number of segments)
        num_samples = num_samples_list[0]
        num_segments = int(num_samples // (segment_duration * fs_list[0]))  # Ensure this is an integer
        print(f"Total number of segments: {num_segments}")

        # Create output folder if it doesn't exist
        os.makedirs(output_folder, exist_ok=True)

        # Iterate through the file in 30-second chunks
        for segment_num in range(num_segments):
            segment_data = {}

            # For each signal, calculate the start and end samples based on its sampling frequency
            for i, label in enumerate(signal_labels):
                fs = fs_list[i]  # Sampling frequency of the current signal
                num_samples = num_samples_list[i]  # Number of samples for the current signal

                # Calculate start and end samples for this signal
                start_sample = segment_num * segment_duration * fs  # Start sample for this signal
                end_sample = (segment_num + 1) * segment_duration * fs  # End sample for this signal

                # Ensure the last segment captures all remaining samples
                if segment_num == num_segments - 1:
                    end_sample = num_samples  # Set the end_sample to the last sample

                # Ensure start_sample and end_sample are integers
                start_sample = int(start_sample)
                end_sample = int(end_sample)

                # Read data for the current signal
                signal_data = edf_file.readSignal(i)[start_sample:end_sample]

                # Resample the signal to the target sampling frequency (128 Hz)
                resampled_signal = resample_signal(signal_data, fs, target_fs)
                segment_data[label] = resampled_signal

            # Save the resampled segment data to a CSV file
            segment_filename = os.path.join(output_folder, f"ucddb015_segment_{segment_num+1}.csv")
            segment_df = pd.DataFrame(segment_data)
            segment_df.to_csv(segment_filename, index=False)

            print(f"Resampled segment saved to {segment_filename}")

        # Close the EDF file
        edf_file._close()

    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage
file_path = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb015.rec'  # Replace with your actual file path
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/resampled_segments'  # Replace with your desired output folder
resample_signals(file_path, output_folder)

import os

def count_segments_in_folder(folder_path):
    # Get the list of all CSV files in the folder
    segment_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]

    # Get the number of segments (CSV files)
    num_segments = len(segment_files)

    print(f"Total number of segments in the folder: {num_segments}")

# Example usage
folder_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/resampled_segments'  # Folder with resampled segments
count_segments_in_folder(folder_path)

"""# **Apnea label segmentation**"""

import pandas as pd
import numpy as np
import os

# Function to convert HH:MM:SS to seconds
def hms_to_seconds(hms):
    try:
        h, m, s = map(int, hms.split(":"))
        return h * 3600 + m * 60 + s
    except ValueError:
        return None

# Function to create apnea label CSV with all segments (including "None" for no event)
def create_apnea_label_csv_from_file(event_file, total_segments, output_folder, segment_duration=30):
    # Open and read the event file
    with open(event_file, 'r') as file:
        lines = file.readlines()

    # List to store the apnea label data
    apnea_label_data = []

    # Parse the event data
    for segment_num in range(1, total_segments + 1):
        # Calculate the start and end time of the current segment
        start_time_sec = (segment_num - 1) * segment_duration
        end_time_sec = segment_num * segment_duration

        # Initialize the apnea label to "None"
        apnea_label = "None"

        # Iterate over each event and check if it falls within the current segment
        for line in lines:
            if line.startswith("Time") or not line.strip():  # Skip header lines or empty lines
                continue

            # Split the line into parts
            parts = line.split()
            if len(parts) < 2:
                continue

            event_time = parts[0]  # Time of the event
            event_type = parts[1]  # Event type (e.g., HYP-C, HYP-O)

            # Convert the event time to seconds
            event_start_sec = hms_to_seconds(event_time)

            # Check if the event is within the current segment
            if event_start_sec is not None and start_time_sec <= event_start_sec < end_time_sec:
                apnea_label = event_type  # Assign the event type to the apnea label
                break  # If an event is found, no need to check further events

        # Append the event label information for the current segment
        apnea_label_data.append({
            'Record': 'ucddb028',  # Replace with your record name
            'Segment Number': segment_num,
            'Apnea Label': apnea_label
        })

    # Create a DataFrame for the apnea labels
    df_apnea_labels = pd.DataFrame(apnea_label_data)

    # Create output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Save the apnea labels to a CSV file
    apnea_label_csv_file = os.path.join(output_folder, 'ucddb028_apnea_label.csv')
    df_apnea_labels.to_csv(apnea_label_csv_file, index=False)

    print(f"Apnea labels saved to {apnea_label_csv_file}")

# Example usage
event_file = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb028_respevt.txt'  # Path to your apnea events file
total_segments = 721  # Total number of 30-second segments in your signal
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/apnea_label'  # Replace with your desired output folder

# Create the CSV file for apnea labels
create_apnea_label_csv_from_file(event_file, total_segments, output_folder)

"""# **sleep stage annotation**"""

import pandas as pd
import os

# Function to map numeric stages to descriptive labels
def map_sleep_stage(stage_num):
    if stage_num == 0:
        return 'Wake'
    elif stage_num == 1:
        return 'REM'
    elif stage_num == 2:
        return 'Stage 1'
    elif stage_num == 3:
        return 'Stage 2'
    elif stage_num == 4:
        return 'Stage 3'
    elif stage_num == 5:
        return 'Stage 4'
    elif stage_num == 6:
        return 'Artifact'
    elif stage_num == 7:
        return 'Indeterminate'
    else:
        return 'Unknown'

# Function to save sleep stages along with record name and segment number
def save_sleep_stages_to_csv(stage_file, total_segments, output_folder, segment_duration=30):
    # Open and read the stage file
    with open(stage_file, 'r') as file:
        lines = file.readlines()

    # List to store the sleep stage data
    sleep_stage_data = []

    # Parse the sleep stage data
    for segment_num in range(1, total_segments + 1):
        # Calculate the start and end time of the current segment
        start_time_sec = (segment_num - 1) * segment_duration
        end_time_sec = segment_num * segment_duration

        # Ensure we have the correct sleep stage for this segment
        stage_idx = segment_num - 1  # Subtract 1 to match the index (0-based)

        if stage_idx < len(lines):
            sleep_stage_num = int(lines[stage_idx].strip())  # Convert the stage value to int
        else:
            sleep_stage_num = 0  # Default to 'Wake' if the stage list is shorter

        # Map numeric stage to a descriptive label
        sleep_stage = map_sleep_stage(sleep_stage_num)

        # Append the sleep stage information for the current segment
        sleep_stage_data.append({
            'Record': 'ucddb028',  # Replace with your record name
            'Segment Number': segment_num,
            'Sleep Stage': sleep_stage
        })

    # Create a DataFrame for the sleep stages
    df_sleep_stages = pd.DataFrame(sleep_stage_data)

    # Create output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Save the sleep stages to a CSV file
    sleep_stage_csv_file = os.path.join(output_folder, 'ucddb028_sleep_stage.csv')
    df_sleep_stages.to_csv(sleep_stage_csv_file, index=False)

    print(f"Sleep stages saved to {sleep_stage_csv_file}")

# Example usage
stage_file = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb028_stage.txt'  # Path to your sleep stages file
total_segments = 721  # Total number of 30-second segments in your signal
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/sleep_stage'  # Replace with your desired output folder

# Create the CSV file for sleep stages
save_sleep_stages_to_csv(stage_file, total_segments, output_folder)

"""# **Displaying different signals PSD**"""

import pyedflib
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import welch

# Function to compute and display the Power Spectral Density (PSD)
def plot_psd(signal, fs, title="Power Spectral Density (PSD)"):
    # Compute the Power Spectral Density using the Welch method
    f, Pxx = welch(signal, fs=fs, nperseg=1024)

    # Plot the PSD
    plt.figure(figsize=(10, 6))
    plt.semilogy(f, Pxx)  # Use semilog scale for better visualization of the low frequencies
    plt.title(title)
    plt.xlabel("Frequency (Hz)")
    plt.ylabel("Power Spectral Density (uV^2/Hz)")
    plt.grid(True)
    plt.show()

# Function to analyze the PSD of the specific signals (EMG, C3A2, C4A1, ECG) from the EDF file
def display_psd_of_signals(file_path):
    try:
        # Open the EDF file
        edf_file = pyedflib.EdfReader(file_path)

        # Get signal labels and sample frequencies
        signal_labels = edf_file.getSignalLabels()
        fs_list = edf_file.getSampleFrequencies()  # List of sampling frequencies for each signal

        # Define signals of interest
        signals_of_interest = ['Lefteye','RightEye','EMG', 'C3A2', 'C4A1', 'ECG','SpO2']  # You can adjust this list as per your needs

        # Check if signals exist and get their index
        signal_indices = [i for i, label in enumerate(signal_labels) if label in signals_of_interest]

        # Iterate over the signals of interest and display the PSD
        for i in signal_indices:
            signal_data = edf_file.readSignal(i)
            signal_label = signal_labels[i]
            fs = fs_list[i]  # Get the sampling frequency of the signal

            print(f"Displaying PSD for {signal_label}...")
            plot_psd(signal_data, fs, title=f"PSD of {signal_label}")

        # Close the EDF file
        edf_file._close()

    except Exception as e:
        print(f"An error occurred: {e}")

# Example usage
file_path = '/content/drive/My Drive/Colab Notebooks/UCDDB/ucddb028.rec'  # Path to your EDF file
display_psd_of_signals(file_path)

"""# **Normalization**"""

import pandas as pd
import os
import numpy as np

# Function to apply Z-score normalization to a signal
def z_score_normalize(signal):
    mean_val = np.mean(signal)  # Mean of the signal
    std_val = np.std(signal)    # Standard deviation of the signal
    normalized_signal = (signal - mean_val) / std_val  # Apply Z-score formula
    return normalized_signal

# Function to normalize all signals in each segment and save the normalized data to a new folder
def normalize_all_segments(input_folder, output_folder, normalization_type='z-score'):
    # Get the list of all CSV files in the input folder (resampled data)
    segment_files = [f for f in os.listdir(input_folder) if f.endswith('.csv')]

    # Create the output folder if it doesn't exist
    os.makedirs(output_folder, exist_ok=True)

    # Iterate over each segment file and apply normalization
    for segment_file in segment_files:
        # Read the segmented data from the CSV file
        segment_filepath = os.path.join(input_folder, segment_file)
        segment_data = pd.read_csv(segment_filepath)

        # Apply normalization to each signal (column) in the segment
        normalized_data = {}
        for column in segment_data.columns:
            signal = segment_data[column].values
            if normalization_type == 'z-score':
                normalized_signal = z_score_normalize(signal)
            else:
                raise ValueError("Invalid normalization type. Use 'z-score'.")

            normalized_data[column] = normalized_signal

        # Save the normalized segment data to a CSV file
        normalized_filename = os.path.join(output_folder, f"{segment_file}")
        normalized_df = pd.DataFrame(normalized_data)
        normalized_df.to_csv(normalized_filename, index=False)

        print(f"Normalized segment saved to {normalized_filename}")

# Example usage
input_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/resampled_segments'  # Folder with resampled files
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/normalized_rec_segments'  # Folder to save normalized files

# Normalize all segments using Z-score normalization
normalize_all_segments(input_folder, output_folder, normalization_type='z-score')

import os

def count_segments_in_folder(folder_path):
    # Get the list of all CSV files in the folder
    segment_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]

    # Get the number of segments (CSV files)
    num_segments = len(segment_files)

    print(f"Total number of segments in the folder: {num_segments}")

# Example usage
folder_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/normalized_rec_segments'  # Folder with resampled segments
count_segments_in_folder(folder_path)

"""# **combining Sleep stages files together**"""

import os
import pandas as pd

# Define the input folder where the sleep stage label files are stored
input_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/sleep_stage'

# List to store all dataframes
all_labels = []

# Loop through each file in the input folder
for filename in os.listdir(input_folder):
    if filename.endswith('sleep_stage.csv'):  # Process only the relevant CSV files
        file_path = os.path.join(input_folder, filename)

        # Read the current label file into a DataFrame
        df = pd.read_csv(file_path)

        # Optionally, you can add a column to indicate which file the data came from
        # df['Source File'] = filename

        # Append the DataFrame to the list
        all_labels.append(df)

# Concatenate all DataFrames into a single DataFrame
merged_labels = pd.concat(all_labels, ignore_index=True)

# Define the output file path where the merged file will be saved
output_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stage.csv'

# Save the merged DataFrame to a CSV file
merged_labels.to_csv(output_file_path, index=False)

print(f"Merged sleep stage labels saved to {output_file_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stage.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stage.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Count the occurrences of each sleep stage in the 'Sleep Stage' column
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Print the counts for each sleep stage
print(sleep_stage_counts)

"""# **removing the unknown segments**"""

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stage.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Remove rows where the 'Sleep Stage' column has the value 'Unknown'
df_cleaned = df[df['Sleep Stage'] != 'Unknown']

# Save the cleaned DataFrame back to a CSV file
output_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stages.csv'  # Update this path
df_cleaned.to_csv(output_file_path, index=False)

# Print the number of rows before and after cleaning
print(f"Original number of rows: {len(df)}")
print(f"Number of rows after removing 'Unknown' labels: {len(df_cleaned)}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stages.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Count the occurrences of each sleep stage in the 'Sleep Stage' column
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Print the counts for each sleep stage
print(sleep_stage_counts)

import os

def count_segments_in_folder(folder_path):
    # Get the list of all CSV files in the folder
    segment_files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]

    # Get the number of segments (CSV files)
    num_segments = len(segment_files)

    print(f"Total number of segments in the folder: {num_segments}")

# Example usage
folder_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/normalized_rec_segments'  # Folder with resampled segments
count_segments_in_folder(folder_path)

!pip install pyentrp

!pip install nolds

"""# **Extract features from EEG**"""

import numpy as np
import pandas as pd
import os
from scipy.stats import skew, kurtosis
from statsmodels.tsa.ar_model import AutoReg
import matplotlib.pyplot as plt
import pywt  # For wavelet transform to detect sleep spindles
import nolds  # For Sample Entropy (complexity)

# Function to extract time-domain features
def time_domain_features(signal):
    # Calculate time-domain features
    mean = np.mean(signal)
    mad = np.mean(np.abs(signal - mean))  # Mean Absolute Deviation (MAD)
    skewness = skew(signal)
    kurt = kurtosis(signal)

    max_value = np.max(signal)  # Maximum value
    min_value = np.min(signal)  # Minimum value

    return [mean, mad, skewness, kurt, max_value, min_value]



# Function to compute complexity (Sample Entropy)
def compute_complexity(signal):
    # Using Sample Entropy (SampEn) from `nolds` library
    return nolds.sampen(signal)

# Function to compute laminarity (a measure of regularity)

# Function to detect and extract sleep spindle features (using Wavelet Transform)
def detect_spindles(eeg_signal, fs, low_freq=12, high_freq=16):
    # Perform continuous wavelet transform (CWT)
    scales = np.arange(1, 256)
    coef, freqs = pywt.cwt(eeg_signal, scales, 'morl', sampling_period=1/fs)

    # Find indices corresponding to the frequency band (12-16 Hz for spindles)
    spindle_band = (freqs >= low_freq) & (freqs <= high_freq)
    spindle_coef = coef[spindle_band, :]

    # Get the number of spindles
    num_spindles = np.count_nonzero(np.abs(spindle_coef) > np.mean(np.abs(spindle_coef)))

    # Calculate amplitude (max value in the spindle band)
    amplitude = np.max(np.abs(spindle_coef))

    # Calculate frequency (mean frequency in the spindle band)
    frequency = np.mean(freqs[spindle_band])


    # Return the spindle features
    return [num_spindles, amplitude, frequency]

# Function to extract features from the EEG signals in each segment
def extract_features_from_segments(signals_folder, output_folder, fs=128, num_segments=10):
    # Get all CSV files from the signals folder (normalized data)
    signal_files = [f for f in os.listdir(signals_folder) if f.endswith('.csv')]

    # Select the first 'num_segments' files for testing
    signal_files = signal_files[8000:10000]

    # Initialize lists to hold features and metadata (record name, segment number)
    all_features = []

    for signal_file in signal_files:
        # Load the normalized signal data
        signal_filepath = os.path.join(signals_folder, signal_file)
        signal_data = pd.read_csv(signal_filepath)

        # Extract the segment number and record name from the file name
        record_name = signal_file.split('_')[0]  # e.g., ucddb002
        segment_number = int(signal_file.split('_')[-1].split('.')[0])  # Extract segment number

        # Extract features for C3A2 and C4A1 (EEG signals)
        c3a2_signal = signal_data['C3A2'].values
        c4a1_signal = signal_data['C4A1'].values

        # Extract time-domain features for both EEG signals
        c3a2_features = time_domain_features(c3a2_signal)
        c4a1_features = time_domain_features(c4a1_signal)



        # Compute complexity for both EEG signals
        c3a2_complexity = compute_complexity(c3a2_signal)
        c4a1_complexity = compute_complexity(c4a1_signal)


        # Detect and extract sleep spindle features for both EEG signals
        c3a2_spindle_features = detect_spindles(c3a2_signal, fs)
        c4a1_spindle_features = detect_spindles(c4a1_signal, fs)

        # Combine all features
        feature_row = [record_name, segment_number] + c3a2_features + c4a1_features + [c3a2_complexity, c4a1_complexity] + c3a2_spindle_features + c4a1_spindle_features
        all_features.append(feature_row)

    # Convert all features to a DataFrame
    feature_columns = [
        'Record', 'Segment Number',
        'C3A2 Mean', 'C3A2 MAD', 'C3A2 Skewness', 'C3A2 Kurtosis',  'C3A2 Max', 'C3A2 Min',
        'C4A1 Mean', 'C4A1 MAD', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min',
        'C3A2 Complexity', 'C4A1 Complexity',
        'C3A2 Spindles Count', 'C3A2 Spindles Amplitude', 'C3A2 Spindles Frequency',
        'C4A1 Spindles Count', 'C4A1 Spindles Amplitude', 'C4A1 Spindles Frequency'
    ]

    # Create a DataFrame and save it to a CSV file
    feature_df = pd.DataFrame(all_features, columns=feature_columns)

    # Save to output folder
    output_filepath = os.path.join(output_folder, 'eeg_features6.csv')
    feature_df.to_csv(output_filepath, index=False)
    print(f"Features saved to {output_filepath}")

# Example usage
signals_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/normalized_rec_segments'  # Folder with normalized signals
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features'  # Folder to save extracted features

# Extract and save features from EEG signals for the first 10 segments
extract_features_from_segments(signals_folder, output_folder, fs=128, num_segments=10)

"""# **Marging EEG signals features**"""

import pandas as pd

# Define file paths
file1_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eeg_features.csv'
file2_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/eeg_features12.csv'
output_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eeg_features.csv'

# Read the two CSV files
df1 = pd.read_csv(file1_path)
df2 = pd.read_csv(file2_path)

# Check if the columns match between the two files (to avoid issues)
if list(df1.columns) == list(df2.columns):
    print("Columns match! Proceeding with merging.")
else:
    print("Warning: Columns don't match. Please check the files.")

# Concatenate the DataFrames
merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)

# Save the merged DataFrame to a new CSV file
merged_df.to_csv(output_path, index=False)

print(f"Merged file saved to {output_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eeg_features.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")

import pandas as pd

# Define file paths
features_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eeg_features.csv'
sleep_stages_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stages.csv'
output_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'

# Read the merged EEG features and sleep stages data
features_df = pd.read_csv(features_file_path)
sleep_stages_df = pd.read_csv(sleep_stages_file_path)

# Merge the two DataFrames on 'Record' and 'Segment Number'
merged_df = pd.merge(features_df, sleep_stages_df, on=['Record', 'Segment Number'], how='left')

# Save the resulting DataFrame with the sleep stages added to a new CSV file
merged_df.to_csv(output_file_path, index=False)

print(f"Data with sleep stages has been saved to {output_file_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")



"""# **Model check with EEG features**

# **balanced 575 segment RF classifier 63.77**
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values

# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Sample 500 segments from each class (sleep stage)
# Group by 'Sleep Stage' and take a random sample of 500 from each group
sampled_df = df.groupby('Sleep Stage').apply(lambda x: x.sample(n=575, random_state=42)).reset_index(drop=True)

# Check the new distribution after sampling
print("Distribution of Sleep Stages after sampling:")
print(sampled_df['Sleep Stage'].value_counts())

# Step 5: Separate the features and the target label
X = sampled_df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = sampled_df['Sleep Stage']  # Labels (sleep stages)

# Step 6: Handle class imbalance using SMOTE (Synthetic Minority Over-sampling Technique)
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42)

# Initialize RandomForest model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

"""# **RF 87.07**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Initialize RandomForest model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Feature importance
feature_importance = model.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,       # Features
    'Importance': feature_importance  # Importance score
})

# Sort the features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the top features
print(feature_importance_df.head())

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance of Each Feature')
plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top
plt.show()


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

"""# **RF 80.05**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import matplotlib.pyplot as plt


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Initialize RandomForest model with more parameters
model = RandomForestClassifier(
    n_estimators=50,           # number of trees (increase for stability)
    criterion='gini',           # or 'entropy' / 'log_loss'
    max_depth=14,             # set an integer limit to prevent overfitting
    min_samples_split=8,        # minimum samples required to split an internal node
    max_features='sqrt',        # number of features to consider for best split ('sqrt', 'log2', or None)
    class_weight='balanced',    # handle class imbalance
    random_state=42,            # reproducibility

)
# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

"""# **RF CV 72.94**"""

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,
                             roc_auc_score, roc_curve, precision_score, recall_score, f1_score)
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

# Step 1: Load data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)
df = df.dropna()

# Step 2: Encode labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 3: Split features and labels
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 4: Initialize 5-Fold CV
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Step 5: Lists to store results
fold_accuracies, fold_roc_aucs = [], []
fold_precisions, fold_recalls, fold_f1s = [], [], []

plt.figure(figsize=(10, 6))

# Step 6: 5-Fold Loop
for fold, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):
    print(f"\n================ Fold {fold} ================")

    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    # Apply SMOTE
    smote = SMOTE(random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

    print("Post-SMOTE class distribution:")
    print(pd.Series(y_train_res).value_counts())

    # Random Forest model
    model = RandomForestClassifier(
        n_estimators=50,
        criterion='gini',
        max_depth=14,
        min_samples_split=8,
        max_features='sqrt',
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )

    # Train
    model.fit(X_train_res, y_train_res)

    # Predict
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)

    # Accuracy and ROC AUC
    acc = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')

    fold_accuracies.append(acc)
    fold_roc_aucs.append(roc_auc)

    print(f"\nFold {fold} Accuracy: {acc * 100:.2f}%")
    print(f"Fold {fold} ROC AUC: {roc_auc:.2f}")

    # Classification report
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    print("Confusion Matrix:")
    print(cm)

    # Per-class metrics
    class_metrics = {}
    for class_idx in range(len(label_encoder.classes_)):
        class_name = label_encoder.classes_[class_idx]
        precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
        recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
        f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]
        tp = cm[class_idx, class_idx]
        fn = cm[class_idx, :].sum() - tp
        fp = cm[:, class_idx].sum() - tp
        tn = cm.sum() - (tp + fn + fp)
        sensitivity = tp / (tp + fn)
        specificity = tn / (tn + fp)

        class_metrics[class_name] = {
            'Precision': precision,
            'Recall (Sensitivity)': recall,
            'F1 Score': f1,
            'Specificity': specificity
        }

    # Print per-class metrics
    for class_name, metrics in class_metrics.items():
        print(f"\nMetrics for {class_name}:")
        for metric, value in metrics.items():
            print(f"{metric}: {value:.2f}")

    # Store average per-fold metrics
    fold_precisions.append(precision_score(y_test, y_pred, average='weighted'))
    fold_recalls.append(recall_score(y_test, y_pred, average='weighted'))
    fold_f1s.append(f1_score(y_test, y_pred, average='weighted'))

    # Plot ROC per class
    for class_idx in range(len(label_encoder.classes_)):
        fpr, tpr, _ = roc_curve(y_test, y_proba[:, class_idx], pos_label=class_idx)
        plt.plot(fpr, tpr, alpha=0.5, label=f'Fold {fold} - {label_encoder.classes_[class_idx]}')

# Step 7: Overall summary
print("\n================ Overall 5-Fold Performance ================")
print(f"Average Accuracy: {np.mean(fold_accuracies)*100:.2f}%  {np.std(fold_accuracies)*100:.2f}%")
print(f"Average ROC AUC: {np.mean(fold_roc_aucs):.2f}  {np.std(fold_roc_aucs):.2f}")
print(f"Average Precision: {np.mean(fold_precisions):.2f}")
print(f"Average Recall: {np.mean(fold_recalls):.2f}")
print(f"Average F1 Score: {np.mean(fold_f1s):.2f}")

# Step 8: Combined ROC plot
plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curves across 5 folds')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(fontsize=8)
plt.show()

"""# **AdaBoost**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

# Step 1: Load the data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

# Display distribution
print("\nDistribution of Sleep Stages:")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and target
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance with SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Optional normalization (not critical for AdaBoost, but helps with base estimator)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize AdaBoost model
base_estimator = DecisionTreeClassifier(
    max_depth=8,                # shallow tree for weak learner
    min_samples_split=5,
    criterion='gini',
    random_state=42
)

adaboost = AdaBoostClassifier(
    estimator=base_estimator,
    n_estimators=120,           # number of weak learners
    learning_rate=0.5,          # controls contribution of each classifier
    algorithm='SAMME',        # SAMME.R uses probabilities (better for multi-class)
    random_state=42
)

# Step 8: Train the model
adaboost.fit(X_train, y_train)

# Step 9: Predictions
y_pred = adaboost.predict(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, adaboost.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and curves
roc_auc = roc_auc_score(y_test, adaboost.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"\nROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, adaboost.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (AdaBoost)')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
from xgboost import XGBClassifier

# Step 1: Load data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

print("\nDistribution of Sleep Stages (before SMOTE):")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and labels
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Normalize features (recommended for XGBoost numeric stability)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize XGBoost model
xgb_model = XGBClassifier(
    n_estimators=70,          # Number of trees
    learning_rate=0.2,         # Step size shrinkage
    max_depth=7,              # Maximum tree depth
    eval_metric='mlogloss',    # Multi-class log loss
    random_state=42,           # Reproducibility
    verbosity=1
)

# Step 8: Train the model
xgb_model.fit(X_train, y_train)

# Step 9: Predictions
y_pred = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, xgb_model.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class Metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and Plot ROC Curve
roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (XGBoost)')
plt.legend(loc='lower right')
plt.show()

"""# **GB Classifier**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)
# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = GradientBoostingClassifier(
    n_estimators=350,          # Number of trees (boosting stages)
    learning_rate=0.1,        # Contribution of each tree
    max_depth=8,               # Maximum depth of the individual trees
    min_samples_split=8,       # Minimum samples required to split an internal node
    min_samples_leaf=2,        # Minimum samples required at each leaf node
    subsample=0.8,             # Fraction of samples to use for fitting each tree
    max_features='sqrt',       # Number of features to consider for each tree
    random_state=42            # Reproducibility
)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)
# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = GradientBoostingClassifier(
    n_estimators=350,          # Number of trees (boosting stages)
    learning_rate=0.1,        # Contribution of each tree
    max_depth=8,               # Maximum depth of the individual trees
    min_samples_split=8,       # Minimum samples required to split an internal node
    min_samples_leaf=2,        # Minimum samples required at each leaf node
    subsample=0.8,             # Fraction of samples to use for fitting each tree
    max_features='sqrt',       # Number of features to consider for each tree
    random_state=42            # Reproducibility
)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()























"""# **EOG signal feature extraction**"""

import numpy as np
import pandas as pd
from scipy.stats import skew, kurtosis
from scipy.signal import welch
import pywt  # For wavelet transform to detect eye blinks
import matplotlib.pyplot as plt

# Function to extract time-domain features
def time_domain_features(signal):
    mean = np.mean(signal)
    mad = np.mean(np.abs(signal - mean))  # Mean Absolute Deviation (MAD)
    skewness = skew(signal)
    kurt = kurtosis(signal)
    rms = np.sqrt(np.mean(signal**2))  # Root Mean Square (RMS)
    max_value = np.max(signal)  # Maximum value
    min_value = np.min(signal)  # Minimum value
    peak_to_peak = np.max(signal) - np.min(signal)  # Peak-to-Peak Amplitude
    zero_crossing = np.count_nonzero(np.diff(np.sign(signal)))  # Zero-Crossing Rate

    return [mean, mad, skewness, kurt, rms, max_value, min_value, peak_to_peak, zero_crossing]

# Function to calculate frequency-domain features (Power Spectral Density)
def frequency_domain_features(signal, fs):
    # Power Spectral Density (PSD) using Welch's method
    f, Pxx = welch(signal, fs, nperseg=1024)

    # Peak frequency (the frequency with the highest power)
    peak_frequency = f[np.argmax(Pxx)]

    return [peak_frequency, np.mean(Pxx), np.std(Pxx)]  # Peak Frequency, Mean Power, 0

# Function to detect eye blinks (based on simple thresholding)
def blink_detection(signal, threshold=0.2):
    # Eye blinks are typically large transient movements, so we can detect peaks above a threshold
    blinks = np.where(np.abs(signal) > threshold)[0]
    num_blinks = len(blinks)
    return num_blinks

# Function to extract all features from EOG signals
def extract_eog_features(eog_signal, fs):
    # Time-domain features
    time_features = time_domain_features(eog_signal)

    # Frequency-domain features
    freq_features = frequency_domain_features(eog_signal, fs)

    # Eye Blink Detection
    blink_count = blink_detection(eog_signal)

    # Combine all features
    features = time_features + freq_features + [blink_count]

    return features

# Function to extract features from the EOG signals in each segment
def extract_features_from_segments(signals_folder, output_folder, fs=128, num_segments=10):
    # Get all CSV files from the signals folder (normalized data)
    signal_files = [f for f in os.listdir(signals_folder) if f.endswith('.csv')]

    # Select the first 'num_segments' files for testing
    signal_files = signal_files[:5000]

    # Initialize lists to hold features and metadata (record name, segment number)
    all_features = []

    for signal_file in signal_files:
        # Load the normalized signal data
        signal_filepath = os.path.join(signals_folder, signal_file)
        signal_data = pd.read_csv(signal_filepath)

        # Extract the segment number and record name from the file name
        record_name = signal_file.split('_')[0]  # e.g., ucddb002
        segment_number = int(signal_file.split('_')[-1].split('.')[0])  # Extract segment number

        # Extract EOG signals (LeftEye and RightEye)
        left_eye_signal = signal_data['Lefteye'].values
        right_eye_signal = signal_data['RightEye'].values

        # Extract features for LeftEye and RightEye signals
        left_eye_features = extract_eog_features(left_eye_signal, fs)
        right_eye_features = extract_eog_features(right_eye_signal, fs)

        # Combine all features
        feature_row = [record_name, segment_number] + left_eye_features + right_eye_features
        all_features.append(feature_row)

    # Convert all features to a DataFrame
    feature_columns = [
        'Record', 'Segment Number',
        'LeftEye Mean', 'LeftEye MAD', 'LeftEye Skewness', 'LeftEye Kurtosis', 'LeftEye RMS', 'LeftEye Max', 'LeftEye Min', 'LeftEye Peak-to-Peak', 'LeftEye Zero-Crossing',
        'RightEye Mean', 'RightEye MAD', 'RightEye Skewness', 'RightEye Kurtosis', 'RightEye RMS', 'RightEye Max', 'RightEye Min', 'RightEye Peak-to-Peak', 'RightEye Zero-Crossing',
        'LeftEye Peak Frequency', 'LeftEye Mean Power', 'LeftEye Power Std Dev', 'LeftEye Blink Count',
        'RightEye Peak Frequency', 'RightEye Mean Power', 'RightEye Power Std Dev', 'RightEye Blink Count'
    ]

    # Create a DataFrame and save it to a CSV file
    feature_df = pd.DataFrame(all_features, columns=feature_columns)

    # Save to output folder
    output_filepath = os.path.join(output_folder, 'eog_features1.csv')
    feature_df.to_csv(output_filepath, index=False)
    print(f"Features saved to {output_filepath}")

# Example usage
signals_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/normalized_rec_segments'  # Folder with normalized signals
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features'  # Folder to save extracted features

# Extract and save features from EOG signals for the first 10 segments
extract_features_from_segments(signals_folder, output_folder, fs=128, num_segments=100)

import pandas as pd

# Define file paths
file1_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/eog_features1.csv'
file2_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/eog_features2.csv'
output_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eog_features.csv'

# Read the two CSV files
df1 = pd.read_csv(file1_path)
df2 = pd.read_csv(file2_path)

# Check if the columns match between the two files (to avoid issues)
if list(df1.columns) == list(df2.columns):
    print("Columns match! Proceeding with merging.")
else:
    print("Warning: Columns don't match. Please check the files.")

# Concatenate the DataFrames
merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)

# Save the merged DataFrame to a new CSV file
merged_df.to_csv(output_path, index=False)

print(f"Merged file saved to {output_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eog_features.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")

import pandas as pd

# Define file paths
features_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_eog_features.csv'
sleep_stages_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stages.csv'
output_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'

# Read the merged EEG features and sleep stages data
features_df = pd.read_csv(features_file_path)
sleep_stages_df = pd.read_csv(sleep_stages_file_path)

# Merge the two DataFrames on 'Record' and 'Segment Number'
merged_df = pd.merge(features_df, sleep_stages_df, on=['Record', 'Segment Number'], how='left')

# Save the resulting DataFrame with the sleep stages added to a new CSV file
merged_df.to_csv(output_file_path, index=False)

print(f"Data with sleep stages has been saved to {output_file_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt  # Add this import statement



# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Initialize RandomForest model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Feature importance
feature_importance = model.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,       # Features
    'Importance': feature_importance  # Importance score
})

# Sort the features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the top features
print(feature_importance_df.head())

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance of Each Feature')
plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top
plt.show()


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt  # Add this import statement



# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Initialize RandomForest model
model = RandomForestClassifier(
    n_estimators=250,           # number of trees (increase for stability)
    criterion='gini',           # or 'entropy' / 'log_loss'
    max_depth=14,             # set an integer limit to prevent overfitting
    min_samples_split=8,        # minimum samples required to split an internal node
    max_features='sqrt',        # number of features to consider for best split ('sqrt', 'log2', or None)
    class_weight='balanced',    # handle class imbalance
    random_state=42,            # reproducibility

)
# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
import numpy as np
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix,
                             roc_auc_score, roc_curve, precision_score, recall_score, f1_score)
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

# Step 1: Load data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)
df = df.dropna()

# Step 2: Encode labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 3: Split features and labels
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 4: Initialize 5-Fold CV
kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Step 5: Lists to store results
fold_accuracies, fold_roc_aucs = [], []
fold_precisions, fold_recalls, fold_f1s = [], [], []

plt.figure(figsize=(10, 6))

# Step 6: 5-Fold Loop
for fold, (train_idx, test_idx) in enumerate(kf.split(X, y), 1):
    print(f"\n================ Fold {fold} ================")

    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]
    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]

    # Apply SMOTE
    smote = SMOTE(random_state=42)
    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)

    print("Post-SMOTE class distribution:")
    print(pd.Series(y_train_res).value_counts())

    # Random Forest model
    model = RandomForestClassifier(
        n_estimators=50,
        criterion='gini',
        max_depth=14,
        min_samples_split=8,
        max_features='sqrt',
        class_weight='balanced',
        random_state=42,
        n_jobs=-1
    )

    # Train
    model.fit(X_train_res, y_train_res)

    # Predict
    y_pred = model.predict(X_test)
    y_proba = model.predict_proba(X_test)

    # Accuracy and ROC AUC
    acc = accuracy_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_proba, multi_class='ovr', average='weighted')

    fold_accuracies.append(acc)
    fold_roc_aucs.append(roc_auc)

    print(f"\nFold {fold} Accuracy: {acc * 100:.2f}%")
    print(f"Fold {fold} ROC AUC: {roc_auc:.2f}")

    # Classification report
    print("\nClassification Report:")
    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    print("Confusion Matrix:")
    print(cm)

    # Per-class metrics
    class_metrics = {}
    for class_idx in range(len(label_encoder.classes_)):
        class_name = label_encoder.classes_[class_idx]
        precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
        recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
        f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]
        tp = cm[class_idx, class_idx]
        fn = cm[class_idx, :].sum() - tp
        fp = cm[:, class_idx].sum() - tp
        tn = cm.sum() - (tp + fn + fp)
        sensitivity = tp / (tp + fn)
        specificity = tn / (tn + fp)

        class_metrics[class_name] = {
            'Precision': precision,
            'Recall (Sensitivity)': recall,
            'F1 Score': f1,
            'Specificity': specificity
        }

    # Print per-class metrics
    for class_name, metrics in class_metrics.items():
        print(f"\nMetrics for {class_name}:")
        for metric, value in metrics.items():
            print(f"{metric}: {value:.2f}")

    # Store average per-fold metrics
    fold_precisions.append(precision_score(y_test, y_pred, average='weighted'))
    fold_recalls.append(recall_score(y_test, y_pred, average='weighted'))
    fold_f1s.append(f1_score(y_test, y_pred, average='weighted'))

    # Plot ROC per class
    for class_idx in range(len(label_encoder.classes_)):
        fpr, tpr, _ = roc_curve(y_test, y_proba[:, class_idx], pos_label=class_idx)
        plt.plot(fpr, tpr, alpha=0.5, label=f'Fold {fold} - {label_encoder.classes_[class_idx]}')

# Step 7: Overall summary
print("\n================ Overall 5-Fold Performance ================")
print(f"Average Accuracy: {np.mean(fold_accuracies)*100:.2f}%  {np.std(fold_accuracies)*100:.2f}%")
print(f"Average ROC AUC: {np.mean(fold_roc_aucs):.2f}  {np.std(fold_roc_aucs):.2f}")
print(f"Average Precision: {np.mean(fold_precisions):.2f}")
print(f"Average Recall: {np.mean(fold_recalls):.2f}")
print(f"Average F1 Score: {np.mean(fold_f1s):.2f}")

# Step 8: Combined ROC plot
plt.plot([0, 1], [0, 1], 'k--')
plt.title('ROC Curves across 5 folds')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.legend(fontsize=8)
plt.show()

"""# **AdaBoost**"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

# Step 1: Load the data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

# Display distribution
print("\nDistribution of Sleep Stages:")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and target
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance with SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Optional normalization (not critical for AdaBoost, but helps with base estimator)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize AdaBoost model
base_estimator = DecisionTreeClassifier(
    max_depth=8,                # shallow tree for weak learner
    min_samples_split=5,
    criterion='gini',
    random_state=42
)

adaboost = AdaBoostClassifier(
    estimator=base_estimator,
    n_estimators=120,           # number of weak learners
    learning_rate=0.5,          # controls contribution of each classifier
    algorithm='SAMME',        # SAMME.R uses probabilities (better for multi-class)
    random_state=42
)

# Step 8: Train the model
adaboost.fit(X_train, y_train)

# Step 9: Predictions
y_pred = adaboost.predict(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, adaboost.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and curves
roc_auc = roc_auc_score(y_test, adaboost.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"\nROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, adaboost.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (AdaBoost)')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
from xgboost import XGBClassifier

# Step 1: Load data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

print("\nDistribution of Sleep Stages (before SMOTE):")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and labels
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Normalize features (recommended for XGBoost numeric stability)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize XGBoost model
xgb_model = XGBClassifier(
    n_estimators=400,          # Number of trees
    learning_rate=0.2,         # Step size shrinkage
    max_depth=10,              # Maximum tree depth
    objective='multi:softprob',# Multi-class classification (probabilities)
    eval_metric='mlogloss',    # Multi-class log loss
    subsample=0.8,             # Randomly sample 80% of training data per tree
    colsample_bytree=0.8,      # Randomly sample 80% of features per tree
    random_state=42,           # Reproducibility
    n_jobs=-1,                 # Use all CPU cores
    verbosity=1
)

# Step 8: Train the model
xgb_model.fit(X_train, y_train)

# Step 9: Predictions
y_pred = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, xgb_model.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class Metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and Plot ROC Curve
roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (XGBoost)')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
from xgboost import XGBClassifier

# Step 1: Load data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

print("\nDistribution of Sleep Stages (before SMOTE):")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and labels
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Normalize features (recommended for XGBoost numeric stability)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize XGBoost model
xgb_model = XGBClassifier(
    n_estimators=120,          # Number of trees
    learning_rate=0.2,         # Step size shrinkage
    max_depth=10,              # Maximum tree depth
    eval_metric='mlogloss',    # Multi-class log loss
    random_state=42,           # Reproducibility
    verbosity=1
)

# Step 8: Train the model
xgb_model.fit(X_train, y_train)

# Step 9: Predictions
y_pred = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, xgb_model.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class Metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and Plot ROC Curve
roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (XGBoost)')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
from sklearn.neural_network import MLPClassifier
import matplotlib.pyplot as plt


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)

# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)

# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())


# Initialize the MLP model
mlp_model = MLPClassifier(
    hidden_layer_sizes=(200,300,400,500),  # Number of neurons in the hidden layer
    activation='relu',  # Activation function
    solver='adam',  # Optimizer
    max_iter=500,
    learning_rate_init=0.001,# Maximum number of iterations
    random_state=42,  # Random seed for reproducibility
)


# Train the MLP model
mlp_model.fit(X_train, y_train)

# Make predictions on the test set
y_pred_mlp = mlp_model.predict(X_test)

# Calculate training and test accuracy for MLP
train_accuracy_mlp = accuracy_score(y_train, mlp_model.predict(X_train))
test_accuracy_mlp = accuracy_score(y_test, y_pred_mlp)


print(f"MLP Training Accuracy: {train_accuracy_mlp * 100:.2f}%")
print(f"MLP Test Accuracy: {test_accuracy_mlp * 100:.2f}%")

# Classification report for precision, recall, F1-score for MLP
print("MLP Classification Report:")
print(classification_report(y_test, y_pred_mlp, target_names=label_encoder.classes_))



# Confusion Matrix for MLP
cm_mlp = confusion_matrix(y_test, y_pred_mlp)
print("MLP Confusion Matrix:")
print(cm_mlp)



"""# **EMG feature extraction**"""

import numpy as np
import pandas as pd
from scipy.stats import skew, kurtosis
from scipy.signal import welch
import matplotlib.pyplot as plt
import os
# Function to extract time-domain features
def time_domain_features(signal):
    mean = np.mean(signal)
    mad = np.mean(np.abs(signal - mean))  # Mean Absolute Deviation (MAD)
    skewness = skew(signal)
    kurt = kurtosis(signal)
    max_value = np.max(signal)  # Maximum value
    min_value = np.min(signal)  # Minimum value
    peak_to_peak = np.max(signal) - np.min(signal)  # Peak-to-Peak Amplitude
    zero_crossing = np.count_nonzero(np.diff(np.sign(signal)))  # Zero-Crossing Rate

    return [mean, mad, skewness, kurt,  max_value, min_value, peak_to_peak, zero_crossing]

# Function to calculate frequency-domain features (Power Spectral Density)
def frequency_domain_features(signal, fs):
    # Power Spectral Density (PSD) using Welch's method
    f, Pxx = welch(signal, fs, nperseg=1024)

    # Peak frequency (the frequency with the highest power)
    peak_frequency = f[np.argmax(Pxx)]

    return [peak_frequency, np.mean(Pxx), np.std(Pxx)]  # Peak Frequency, Mean Power, Standard Deviation of Power

# Function to detect muscle bursts (based on a simple thresholding)
def muscle_burst_detection(signal, threshold_factor=2):

    threshold = 2
    # Detect bursts above the threshold
    bursts = np.where(np.abs(signal) > threshold)[0]
    num_bursts = len(bursts)

    return num_bursts

# Function to extract all features from EMG signals
def extract_emg_features(emg_signal, fs):
    # Time-domain features
    time_features = time_domain_features(emg_signal)

    # Frequency-domain features
    freq_features = frequency_domain_features(emg_signal, fs)

    # Muscle Burst Detection
    burst_count = muscle_burst_detection(emg_signal)

    # Combine all features
    features = time_features + freq_features + [burst_count]

    return features

# Function to extract features from the EMG signals in each segment
def extract_features_from_segments(signals_folder, output_folder, fs=128, num_segments=10):
    # Get all CSV files from the signals folder (normalized data)
    signal_files = [f for f in os.listdir(signals_folder) if f.endswith('.csv')]

    # Select the first 'num_segments' files for testing
    signal_files = signal_files[:10000]

    # Initialize lists to hold features and metadata (record name, segment number)
    all_features = []

    for signal_file in signal_files:
        # Load the normalized signal data
        signal_filepath = os.path.join(signals_folder, signal_file)
        signal_data = pd.read_csv(signal_filepath)

        # Extract the segment number and record name from the file name
        record_name = signal_file.split('_')[0]  # e.g., ucddb002
        segment_number = int(signal_file.split('_')[-1].split('.')[0])  # Extract segment number

        # Extract the EMG signal
        emg_signal = signal_data['EMG'].values

        # Extract features for the EMG signal
        emg_features = extract_emg_features(emg_signal, fs)

        # Combine all features
        feature_row = [record_name, segment_number] + emg_features
        all_features.append(feature_row)

    # Convert all features to a DataFrame
    feature_columns = [
        'Record', 'Segment Number',
        'EMG Mean', 'EMG MAD', 'EMG Skewness', 'EMG Kurtosis',  'EMG Max', 'EMG Min', 'EMG Peak-to-Peak', 'EMG Zero-Crossing',
        'EMG Peak Frequency', 'EMG Mean Power', 'EMG Power Std Dev', 'EMG Burst Count'
    ]

    # Create a DataFrame and save it to a CSV file
    feature_df = pd.DataFrame(all_features, columns=feature_columns)

    # Save to output folder
    output_filepath = os.path.join(output_folder, 'emg_features1.csv')
    feature_df.to_csv(output_filepath, index=False)
    print(f"Features saved to {output_filepath}")

# Example usage
signals_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/normalized_rec_segments'  # Folder with normalized signals
output_folder = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features'  # Folder to save extracted features

# Extract and save features from EMG signals for the first 10 segments
extract_features_from_segments(signals_folder, output_folder, fs=128, num_segments=200)

import pandas as pd

# Define file paths
file1_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_emg_features.csv'
file2_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/emg_features3.csv'
output_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_emg_features.csv'

# Read the two CSV files
df1 = pd.read_csv(file1_path)
df2 = pd.read_csv(file2_path)

# Check if the columns match between the two files (to avoid issues)
if list(df1.columns) == list(df2.columns):
    print("Columns match! Proceeding with merging.")
else:
    print("Warning: Columns don't match. Please check the files.")

# Concatenate the DataFrames
merged_df = pd.concat([df1, df2], axis=0, ignore_index=True)

# Save the merged DataFrame to a new CSV file
merged_df.to_csv(output_path, index=False)

print(f"Merged file saved to {output_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_emg_features.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")

import pandas as pd

# Define file paths
features_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_emg_features.csv'
sleep_stages_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/all_sleep_stages.csv'
output_file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

# Read the merged EEG features and sleep stages data
features_df = pd.read_csv(features_file_path)
sleep_stages_df = pd.read_csv(sleep_stages_file_path)

# Merge the two DataFrames on 'Record' and 'Segment Number'
merged_df = pd.merge(features_df, sleep_stages_df, on=['Record', 'Segment Number'], how='left')

# Save the resulting DataFrame with the sleep stages added to a new CSV file
merged_df.to_csv(output_file_path, index=False)

print(f"Data with sleep stages has been saved to {output_file_path}")

import pandas as pd

# Define the path to your CSV file
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'  # Update this path

# Read the CSV file into a DataFrame
df = pd.read_csv(file_path)

# Get the number of rows (first element of the shape tuple)
num_rows = df.shape[0]

# Alternatively, you can use len(df) to get the number of rows
# num_rows = len(df)

print(f"The number of rows in the file is: {num_rows}")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt  # Add this import statement


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Initialize RandomForest model
model = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Feature importance
feature_importance = model.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,       # Features
    'Importance': feature_importance  # Importance score
})

# Sort the features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the top features
print(feature_importance_df.head())

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance of Each Feature')
plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top
plt.show()


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
import numpy as np
import matplotlib.pyplot as plt  # Add this import statement



# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Initialize RandomForest model
model = RandomForestClassifier(
    n_estimators=250,           # number of trees (increase for stability)
    criterion='gini',           # or 'entropy' / 'log_loss'
    max_depth=14,             # set an integer limit to prevent overfitting
    min_samples_split=8,        # minimum samples required to split an internal node
    max_features='sqrt',        # number of features to consider for best split ('sqrt', 'log2', or None)
    class_weight='balanced',    # handle class imbalance
    random_state=42,            # reproducibility

)
# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt

# Step 1: Load the data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

# Display distribution
print("\nDistribution of Sleep Stages:")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and target
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance with SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Optional normalization (not critical for AdaBoost, but helps with base estimator)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize AdaBoost model
base_estimator = DecisionTreeClassifier(
    max_depth=8,                # shallow tree for weak learner
    min_samples_split=5,
    criterion='gini',
    random_state=42
)

adaboost = AdaBoostClassifier(
    estimator=base_estimator,
    n_estimators=120,           # number of weak learners
    learning_rate=0.5,          # controls contribution of each classifier
    algorithm='SAMME',        # SAMME.R uses probabilities (better for multi-class)
    random_state=42
)

# Step 8: Train the model
adaboost.fit(X_train, y_train)

# Step 9: Predictions
y_pred = adaboost.predict(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, adaboost.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and curves
roc_auc = roc_auc_score(y_test, adaboost.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"\nROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, adaboost.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (AdaBoost)')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    precision_score, recall_score, f1_score, roc_auc_score, roc_curve
)
import matplotlib.pyplot as plt
from xgboost import XGBClassifier

# Step 1: Load data
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess
print(df.isnull().sum())
df = df.dropna()

print("\nDistribution of Sleep Stages (before SMOTE):")
print(df['Sleep Stage'].value_counts())

# Step 3: Encode target labels
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Split features and labels
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
y = df['Sleep Stage']

# Step 5: Handle imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)

# Step 6: Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(
    X_res, y_res, test_size=0.2, random_state=42, stratify=y_res
)

# Normalize features (recommended for XGBoost numeric stability)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("Training set class distribution:")
print(pd.Series(y_train).value_counts())
print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

# Step 7: Initialize XGBoost model
xgb_model = XGBClassifier(
    n_estimators=120,          # Number of trees
    learning_rate=0.2,         # Step size shrinkage
    max_depth=10,              # Maximum tree depth
    eval_metric='mlogloss',    # Multi-class log loss
    random_state=42,           # Reproducibility
    verbosity=1
)

# Step 8: Train the model
xgb_model.fit(X_train, y_train)

# Step 9: Predictions
y_pred = xgb_model.predict(X_test)
y_pred_proba = xgb_model.predict_proba(X_test)

# Step 10: Accuracy
train_acc = accuracy_score(y_train, xgb_model.predict(X_train))
test_acc = accuracy_score(y_test, y_pred)

print(f"\nTraining Accuracy: {train_acc * 100:.2f}%")
print(f"Test Accuracy: {test_acc * 100:.2f}%")

# Step 11: Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Step 12: Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("\nConfusion Matrix:")
print(cm)

# Step 13: Per-class Metrics
class_metrics = {}
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 14: ROC AUC and Plot ROC Curve
roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC Score: {roc_auc:.2f}")

plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]}')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for Each Sleep Stage (XGBoost)')
plt.legend(loc='lower right')
plt.show()











import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer

# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data1(df):
    # Drop any rows with missing values
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns

# Step 2: Replace missing numerical values with the mean (SimpleImputer)
    imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median' or 'most_frequent' if needed
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    # Separate the features and target
    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    # Handle class imbalance using SMOTE
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess data for each signal
X1, y1, label_encoder1 = preprocess_data(df1)
X2, y2, label_encoder2 = preprocess_data(df2)
X3, y3, label_encoder3 = preprocess_data(df3)

# Step 3: Split each dataset into training and testing sets
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)
X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)

# Step 4: Initialize the models for each signal
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42)
svm_model = SVC(probability=True, random_state=42)  # Use probability=True for VotingClassifier

# Step 5: Train each model for each signal
rf_model.fit(X_train1, y_train1)
gb_model.fit(X_train2, y_train2)
svm_model.fit(X_train3, y_train3)

# Step 6: Create the VotingClassifier for final classification
voting_clf = VotingClassifier(estimators=[
    ('rf', rf_model),
    ('gb', gb_model),
    ('svm', svm_model)
], voting='soft')  # Use 'soft' voting for probability-based classification

# Train the voting classifier on one of the signal datasets (can use any of them)
voting_clf.fit(X_train1, y_train1)

# Step 7: Evaluate the performance of the voting classifier
y_pred = voting_clf.predict(X_test1)

# Print the classification report
print("Classification Report for Voting Classifier (on Signal 1):")
print(classification_report(y_test1, y_pred, target_names=label_encoder1.classes_))

# Calculate accuracy
accuracy = accuracy_score(y_test1, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix



# Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = GradientBoostingClassifier(
    n_estimators=350,          # Number of trees (boosting stages)
    learning_rate=0.1,        # Contribution of each tree
    max_depth=8,               # Maximum depth of the individual trees
    min_samples_split=8,       # Minimum samples required to split an internal node
    min_samples_leaf=2,        # Minimum samples required at each leaf node
    subsample=0.8,             # Fraction of samples to use for fitting each tree
    max_features='sqrt',       # Number of features to consider for each tree
    random_state=42            # Reproducibility
)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix



# Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder


# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage','C3A2 Mean', 'C3A2 MAD', 'C3A2 Skewness', 'C3A2 Kurtosis',  'C3A2 Max', 'C3A2 Min',
        'C4A1 Mean', 'C4A1 MAD', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min',
        'C3A2 Spindles Frequency',
         'C4A1 Spindles Frequency'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage','LeftEye Mean', 'LeftEye MAD', 'LeftEye Skewness', 'LeftEye Kurtosis', 'LeftEye RMS', 'LeftEye Max', 'LeftEye Min', 'LeftEye Peak-to-Peak',
       'RightEye MAD', 'RightEye RMS', 'RightEye Max', 'RightEye Min', 'RightEye Peak-to-Peak', 'RightEye Zero-Crossing',
        'LeftEye Peak Frequency', 'LeftEye Mean Power', 'LeftEye Power Std Dev',
        'RightEye Mean Power', 'RightEye Power Std Dev', 'RightEye Blink Count'])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage','EMG Mean', 'EMG Max', 'EMG Min', 'EMG Peak-to-Peak',
       'EMG Mean Power'])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = GradientBoostingClassifier(
    n_estimators=350,          # Number of trees (boosting stages)
    learning_rate=0.1,        # Contribution of each tree
    max_depth=8,               # Maximum depth of the individual trees
    min_samples_split=8,       # Minimum samples required to split an internal node
    min_samples_leaf=2,        # Minimum samples required at each leaf node
    subsample=0.8,             # Fraction of samples to use for fitting each tree
    max_features='sqrt',       # Number of features to consider for each tree
    random_state=42            # Reproducibility
)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer

# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage','C3A2 Mean', 'C3A2 MAD', 'C3A2 Skewness', 'C3A2 Kurtosis',  'C3A2 Max', 'C3A2 Min',
        'C4A1 Mean', 'C4A1 MAD', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min',
        'C3A2 Spindles Frequency',
         'C4A1 Spindles Frequency'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage','LeftEye Mean', 'LeftEye MAD', 'LeftEye Skewness', 'LeftEye Kurtosis', 'LeftEye RMS', 'LeftEye Max', 'LeftEye Min', 'LeftEye Peak-to-Peak',
       'RightEye MAD', 'RightEye RMS', 'RightEye Max', 'RightEye Min', 'RightEye Peak-to-Peak', 'RightEye Zero-Crossing',
        'LeftEye Peak Frequency', 'LeftEye Mean Power', 'LeftEye Power Std Dev',
        'RightEye Mean Power', 'RightEye Power Std Dev', 'RightEye Blink Count'])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage','EMG Mean', 'EMG Kurtosis',  'EMG Max', 'EMG Min', 'EMG Peak-to-Peak',
       'EMG Mean Power'])
# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'

# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# Step 3: Split the data into training and testing sets using the same segments for all signals
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)

# Step 4: Initialize the base models for each signal
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42)
svm_model = SVC(probability=True, random_state=42)  # Use probability=True for StackingClassifier

# Step 5: Define the meta-model (a simple Logistic Regression)
meta_model = LogisticRegression()

# Step 6: Create the StackingClassifier using base models and meta-model
stacking_clf = StackingClassifier(estimators=[
    ('rf', rf_model),
    ('gb', gb_model),
    ('svm', svm_model)
], final_estimator=meta_model)

# Step 7: Train the StackingClassifier on the training data
stacking_clf.fit(X_train, y_train)

# Step 8: Evaluate the performance of the stacking classifier
y_pred = stacking_clf.predict(X_test)

# Print the classification report
print("Classification Report for Stacking Classifier:")
print(classification_report(y_test, y_pred, target_names=label_encoder1.classes_))

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy (Stacking): {accuracy * 100:.2f}%")

!pip install catboost

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from catboost import CatBoostClassifier
from sklearn.ensemble import RandomForestClassifier


# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 3: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage') for each signal
X1 = df1_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage', 'C3A2 Mean', 'C3A2 MAD', 'C3A2 Skewness', 'C3A2 Kurtosis', 'C3A2 Max', 'C3A2 Min',
        'C4A1 Mean', 'C4A1 MAD', 'C4A1 Skewness', 'C4A1 Kurtosis', 'C4A1 Max', 'C4A1 Min', 'C3A2 Spindles Frequency', 'C4A1 Spindles Frequency'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage', 'LeftEye Mean', 'LeftEye MAD', 'LeftEye Skewness', 'LeftEye Kurtosis', 'LeftEye RMS', 'LeftEye Max', 'LeftEye Min', 'LeftEye Peak-to-Peak',
       'RightEye MAD', 'RightEye RMS', 'RightEye Max', 'RightEye Min', 'RightEye Peak-to-Peak', 'RightEye Zero-Crossing',
        'LeftEye Peak Frequency', 'LeftEye Mean Power', 'LeftEye Power Std Dev', 'RightEye Mean Power', 'RightEye Power Std Dev', 'RightEye Blink Count'])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage', 'EMG Mean', 'EMG Kurtosis', 'EMG Max', 'EMG Min', 'EMG Peak-to-Peak', 'EMG Mean Power'])

# Clean feature names to remove whitespaces (LightGBM)
X_res1 = pd.DataFrame(X1)
X_res1.columns = [col.replace(' ', '_') for col in X_res1.columns]

X_res2 = pd.DataFrame(X2)
X_res2.columns = [col.replace(' ', '_') for col in X_res2.columns]

X_res3 = pd.DataFrame(X3)
X_res3.columns = [col.replace(' ', '_') for col in X_res3.columns]

# Step 4: Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res1, y_res1 = smote.fit_resample(X_res1, df1_processed['Sleep Stage'])
X_res2, y_res2 = smote.fit_resample(X_res2, df2_processed['Sleep Stage'])
X_res3, y_res3 = smote.fit_resample(X_res3, df3_processed['Sleep Stage'])

# Ensure all three signals have the same number of samples after resampling
X_res = pd.concat([X_res1, X_res2, X_res3], axis=1)
y_res = y_res1  # Assuming all signals have the same 'Sleep Stage'

# Step 5: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)

# Step 6: Initialize the powerful base models for each signal
xgb_model = XGBClassifier(n_estimators=400, learning_rate=0.2, max_depth=10, random_state=42)

rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

catboost_model = CatBoostClassifier(
    iterations=200, depth=5, learning_rate=0.05, random_seed=42, verbose=0
)

# Step 7: Define the meta-model (a simple Logistic Regression)
meta_model = LogisticRegression()

# Step 8: Create the StackingClassifier using base models and meta-model
stacking_clf = StackingClassifier(estimators=[
    ('xgb', xgb_model),
    ('rf', rf_model),
    ('catboost', catboost_model)  # Added CatBoost as another base model
], final_estimator=meta_model)

# Step 9: Train the StackingClassifier on the training data
stacking_clf.fit(X_train, y_train)

# Step 10: Evaluate the performance of the stacking classifier
y_pred = stacking_clf.predict(X_test)

# Print the classification report
print("Classification Report for Stacking Classifier:")
print(classification_report(y_test, y_pred, target_names=label_encoder1.classes_))

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy (Stacking): {accuracy * 100:.2f}%")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)
# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

rf_model = RandomForestClassifier(n_estimators=30, random_state=42)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt


# Step 1: Load the data (merged features and sleep stages)
file_path = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
df = pd.read_csv(file_path)

# Step 2: Preprocess the data
# Check for missing values
print(df.isnull().sum())

# Drop any rows with missing values (if any)
df = df.dropna()

# Step 4: Check the distribution of 'Sleep Stage' after imputation
sleep_stage_counts = df['Sleep Stage'].value_counts()

# Display the count of segments for each sleep stage class
print("\nDistribution of Sleep Stages (number of segments per class):")
print(sleep_stage_counts)
# Step 3: Encode the 'Sleep Stage' labels into numerical values
label_encoder = LabelEncoder()
df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

# Step 4: Separate the features and the target label
X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])  # Features (drop 'Record' and 'Segment Number')
y = df['Sleep Stage']  # Labels (sleep stages)
# Handle class imbalance using SMOTE
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X, y)
# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

from sklearn.ensemble import GradientBoostingClassifier

# Initialize the GradientBoosting model
model = GradientBoostingClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.1,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42  # Random seed for reproducibility
)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier



# Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number','Sleep Stage',  'C3A2 Mean', 'C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min',   'C3A2 Spindles Frequency',  'C4A1 Spindles Frequency'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number','Sleep Stage', 'LeftEye Mean',  'LeftEye Skewness', 'LeftEye Kurtosis', 'LeftEye RMS', 'LeftEye Min', 'LeftEye Peak-to-Peak',
      'RightEye MAD',  'RightEye RMS', 'RightEye Min', 'RightEye Peak-to-Peak', 'RightEye Zero-Crossing',   'LeftEye Peak Frequency', 'LeftEye Mean Power', 'LeftEye Power Std Dev', 'RightEye Mean Power', ])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage', 'EMG Mean', 'EMG Kurtosis', 'EMG Max', 'EMG Min', 'EMG Peak-to-Peak', 'EMG Mean Power'])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())
model = XGBClassifier(
    n_estimators=240,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=8,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier



# Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number','Sleep Stage'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number','Sleep Stage' ])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())
model = XGBClassifier(
    n_estimators=240,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=8,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
label_encoder = LabelEncoder()

y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)  # Or use your chosen model

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")


# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_.astype(str)))  # Ensure classes are strings

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt



# Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)
df2_processed, label_encoder2 = preprocess_data(df2)
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number','Sleep Stage'])
X2 = df2_processed.drop(columns=['Record', 'Segment Number','Sleep Stage' ])
X3 = df3_processed.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)


label_encoder = LabelEncoder()

y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)  # Or use your chosen model

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")


# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_.astype(str)))  # Ensure classes are strings

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt



# Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'

df1 = pd.read_csv(file_path1)

# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df1_processed, label_encoder1 = preprocess_data(df1)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X1 = df1_processed.drop(columns=['Record', 'Segment Number','Sleep Stage'])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X1], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df1_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)


label_encoder = LabelEncoder()

y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)  # Or use your chosen model

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")


# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_.astype(str)))  # Ensure classes are strings

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)



# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

# Feature importance
feature_importance = model.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,       # Features
    'Importance': feature_importance  # Importance score
})

# Sort the features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the top features
print(feature_importance_df.head())

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance of Each Feature')
plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt



# Load the data for each signal
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'

df2 = pd.read_csv(file_path2)


# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df2_processed, label_encoder2 = preprocess_data(df2)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X2 = df2_processed.drop(columns=['Record', 'Segment Number','Sleep Stage' ])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X2], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df2_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = XGBClassifier(
    n_estimators=450,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)


label_encoder = LabelEncoder()

y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)  # Or use your chosen model

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")


# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_.astype(str)))  # Ensure classes are strings

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Feature importance
feature_importance = model.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,       # Features
    'Importance': feature_importance  # Importance score
})

# Sort the features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the top features
print(feature_importance_df.head())

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance of Each Feature')
plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top
plt.show()


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
import matplotlib.pyplot as plt



# Load the data for each signal
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df3 = pd.read_csv(file_path2)


# Function to preprocess the data (Handle missing values, encode labels, etc.)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    return df, label_encoder

# Preprocess each signal's data
df3_processed, label_encoder3 = preprocess_data(df3)

# Step 1: Drop non-feature columns ('Record', 'Segment Number', and 'Sleep Stage')
X3 = df3_processed.drop(columns=['Record', 'Segment Number','Sleep Stage' ])

# Step 2: Concatenate the features from all three signals
X_combined = pd.concat([X3], axis=1)  # Concatenate along columns (features)

# Step 3: Handle class imbalance using SMOTE
y = df3_processed['Sleep Stage']  # Assuming all signals have the same 'Sleep Stage'
smote = SMOTE(random_state=42)
X_res, y_res = smote.fit_resample(X_combined, y)

# ,'C3A2 Mean',  'C3A2 Kurtosis', 'C3A2 Min','C4A1 Mean', 'C4A1 Skewness', 'C4A1 Kurtosis',  'C4A1 Max', 'C4A1 Min','C3A2 Spindles Frequency',   'C4A1 Spindles Frequency'
# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.2, random_state=42, stratify=y_res)
# Print the class distribution for training and test sets
print("Training set class distribution:")
print(pd.Series(y_train).value_counts())

print("\nTest set class distribution:")
print(pd.Series(y_test).value_counts())

model = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)


label_encoder = LabelEncoder()

y_train = label_encoder.fit_transform(y_train)
y_test = label_encoder.transform(y_test)


# Train the model
model.fit(X_train, y_train)

# Make predictions on the test set
y_pred = model.predict(X_test)  # Or use your chosen model

# Calculate training and test accuracy
train_accuracy = accuracy_score(y_train, model.predict(X_train))
test_accuracy = accuracy_score(y_test, y_pred)

# Print training and test accuracies
print(f"Training Accuracy: {train_accuracy * 100:.2f}%")
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")


# Classification report for precision, recall, F1-score
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=label_encoder.classes_.astype(str)))  # Ensure classes are strings

# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Feature importance
feature_importance = model.feature_importances_

# Create a DataFrame for better visualization
feature_importance_df = pd.DataFrame({
    'Feature': X_train.columns,       # Features
    'Importance': feature_importance  # Importance score
})

# Sort the features by importance in descending order
feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)

# Display the top features
print(feature_importance_df.head())

# Plot feature importance
plt.figure(figsize=(10, 6))
plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])
plt.xlabel('Feature Importance')
plt.ylabel('Feature')
plt.title('Feature Importance of Each Feature')
plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top
plt.show()


# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve

from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
# Confusion Matrix
cm = confusion_matrix(y_test1, y_pred)
print("Confusion Matrix:")
print(cm)
label_encoder = LabelEncoder()

# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.4f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

# Define the confusion matrix
conf_matrix = np.array([[1294,  67,  59,   5,   7,  32],
                        [ 99, 1185,  90,   9,   7,  74],
                        [ 59,  107, 1215,  34,  27,  22],
                        [  1,    4,    4, 1444,  10,   2],
                        [  1,    0,    8,   31, 1423,   2],
                        [ 25,   97,   39,    1,   2, 1300]])

# Create a heatmap of the confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt="d", cmap="Blues", cbar=False, annot_kws={"size": 12},
            xticklabels=["REM", "Stage 1", "Stage 2", "Stage 3", "Stage 4", "Wake"],
            yticklabels=["REM", "Stage 1", "Stage 2", "Stage 3", "Stage 4", "Wake"])

# Add labels and title
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.title('Confusion Matrix Heatmap', fontsize=16)

# Show the plot
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix

# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median' or 'most_frequent' if needed
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    # Separate the features and target
    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    # Handle class imbalance using SMOTE
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess data for each signal
X1, y1, label_encoder1 = preprocess_data(df1)
X2, y2, label_encoder2 = preprocess_data(df2)
X3, y3, label_encoder3 = preprocess_data(df3)

# Step 3: Split each dataset into training and testing sets
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)
X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)

# Step 4: Initialize the models for each signal
model1 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model2 = XGBClassifier(
    n_estimators=450,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model3 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)

# Step 5: Train each model for each signal
model1.fit(X_train1, y_train1)
model2.fit(X_train2, y_train2)
model3.fit(X_train3, y_train3)

# Step 6: Create the VotingClassifier for final classification
voting_clf = VotingClassifier(estimators=[
    ('rf', model1),
    ('gb', model2),
    ('svm', model3)
], voting='soft')  # Use 'soft' voting for probability-based classification

# Train the voting classifier on one of the signal datasets (can use any of them)
voting_clf.fit(X_train1, y_train1)

# Step 7: Evaluate the performance of the voting classifier
y_pred = voting_clf.predict(X_test1)

# Print the classification report
print("Classification Report for Voting Classifier (on Signal 1):")
print(classification_report(y_test1, y_pred, target_names=label_encoder1.classes_))

# Calculate accuracy
accuracy = accuracy_score(y_test1, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")


from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix
from xgboost import XGBClassifier
import matplotlib.pyplot as plt
# Confusion Matrix
cm = confusion_matrix(y_test, y_pred)
print("Confusion Matrix:")
print(cm)

# Initialize dictionary to store metrics
class_metrics = {}

# Calculate precision, recall, f1 score for each class
for class_idx in range(len(label_encoder.classes_)):
    class_name = label_encoder.classes_[class_idx]

    # Precision, Recall, F1 Score for the specific class
    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    # Sensitivity (Recall) and Specificity for the specific class
    tp = cm[class_idx, class_idx]  # True Positive
    fn = cm[class_idx, :].sum() - tp  # False Negative
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)  # True Negative
    fp = cm[:, class_idx].sum() - tp  # False Positive

    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    # Store metrics for this class
    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

# Print metrics for each class
for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# Step 12: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"ROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder.classes_)):
    fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier

# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median' or 'most_frequent' if needed
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    # Separate the features and target
    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    # Handle class imbalance using SMOTE
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess data for each signal
X1, y1, label_encoder1 = preprocess_data(df1)
X2, y2, label_encoder2 = preprocess_data(df2)
X3, y3, label_encoder3 = preprocess_data(df3)

# Step 3: Normalize the features using StandardScaler (Z-score normalization)
scaler = StandardScaler()

# Fit the scaler on the training data and apply to all data (training and test sets)
X1 = scaler.fit_transform(X1)
X2 = scaler.fit_transform(X2)
X3 = scaler.fit_transform(X3)

# Step 3: Split each dataset into training and testing sets
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)
X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)

# Step 4: Initialize the models for each signal
model1 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model2 = XGBClassifier(
    n_estimators=450,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model3 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)

# Step 5: Train each model for each signal
model1.fit(X_train1, y_train1)
model2.fit(X_train2, y_train2)
model3.fit(X_train3, y_train3)

# Step 6: Create the VotingClassifier for final classification
voting_clf = VotingClassifier(estimators=[
    ('rf', model1),
    ('gb', model2),
    ('svm', model3)
], voting='soft')  # Use 'soft' voting for probability-based classification

# Train the voting classifier on one of the signal datasets (can use any of them)
voting_clf.fit(X_train1, y_train1)

# Step 7: Evaluate the performance of the voting classifier
y_pred = voting_clf.predict(X_test1)

# Print the classification report
print("Classification Report for Voting Classifier (on Signal 1):")
print(classification_report(y_test1, y_pred, target_names=label_encoder1.classes_))

# Calculate accuracy
accuracy = accuracy_score(y_test1, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")



# Step 12: Calculate precision, recall, and F1-score for each class
print("\nMetrics for Each Class:")
for class_idx in range(len(label_encoder1.classes_)):
    class_name = label_encoder1.classes_[class_idx]

    precision = precision_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test1, y_pred, average=None, labels=[class_idx])[0]

    print(f"\nMetrics for class '{class_name}':")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1-score: {f1:.2f}")

# Step 13: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test1, voting_clf.predict_proba(X_test1), multi_class='ovr', average='weighted')
print(f"\nROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder1.classes_)):
    fpr, tpr, _ = roc_curve(y_test1, voting_clf.predict_proba(X_test1)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder1.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, cross_validate
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score, roc_auc_score, roc_curve
from sklearn.preprocessing import LabelEncoder, StandardScaler
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer
from xgboost import XGBClassifier
import matplotlib.pyplot as plt

# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median' or 'most_frequent' if needed
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    # Separate the features and target
    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    # Handle class imbalance using SMOTE
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess data for each signal
X1, y1, label_encoder1 = preprocess_data(df1)
X2, y2, label_encoder2 = preprocess_data(df2)
X3, y3, label_encoder3 = preprocess_data(df3)

# Step 3: Normalize the features using StandardScaler (Z-score normalization)
scaler = StandardScaler()

# Fit the scaler on the training data and apply to all data (training and test sets)
X1 = scaler.fit_transform(X1)
X2 = scaler.fit_transform(X2)
X3 = scaler.fit_transform(X3)

# Step 4: Combine all signals' features into one feature set (X_combined)
X_combined = pd.concat([pd.DataFrame(X1), pd.DataFrame(X2), pd.DataFrame(X3)], axis=1)  # Concatenate along columns (features)

# Step 5: Split the data into training and testing sets for each signal
X_train, X_test, y_train, y_test = train_test_split(X_combined, y1, test_size=0.2, random_state=42, stratify=y1)

# Convert X_train and X_test to numpy arrays for compatibility with XGBoost
X_train = X_train.to_numpy()
X_test = X_test.to_numpy()

# Step 6: Initialize the models for each signal (using XGBoost, RandomForest, and GradientBoosting as base models)
model1 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model2 = XGBClassifier(
    n_estimators=450,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model3 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
# Step 7: Train each model for each signal with 5-fold cross-validation
cv_results1 = cross_validate(model1, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)
cv_results2 = cross_validate(model2, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)
cv_results3 = cross_validate(model3, X_train, y_train, cv=5, scoring='accuracy', return_train_score=True)

print(f"XGBClassifier Cross-Validation Accuracy: {cv_results1['test_score'].mean():.2f}")
print(f"GradientBoostingClassifier Cross-Validation Accuracy: {cv_results2['test_score'].mean():.2f}")
print(f"RandomForestClassifier Cross-Validation Accuracy: {cv_results3['test_score'].mean():.2f}")

# Step 8: Create the VotingClassifier for final classification
voting_clf = VotingClassifier(estimators=[
    ('xgb', model1),
    ('gb', model2),
    ('rf', model3)
], voting='soft')  # Use 'soft' voting for probability-based classification

# Step 9: Train the voting classifier on the combined dataset
voting_clf.fit(X_train, y_train)

# Step 10: Evaluate the performance of the voting classifier
y_pred = voting_clf.predict(X_test)

# Step 11: Print the classification report
print("Classification Report for Voting Classifier (on Combined Signal Features):")
print(classification_report(y_test, y_pred, target_names=label_encoder1.classes_))

# Step 12: Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Step 13: Calculate precision, recall, and F1-score for each class
print("\nMetrics for Each Class:")
for class_idx in range(len(label_encoder1.classes_)):
    class_name = label_encoder1.classes_[class_idx]

    precision = precision_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test, y_pred, average=None, labels=[class_idx])[0]

    print(f"\nMetrics for class '{class_name}':")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"F1-score: {f1:.2f}")

# Step 14: Calculate ROC AUC and plot ROC curve for each class
roc_auc = roc_auc_score(y_test, voting_clf.predict_proba(X_test), multi_class='ovr', average='weighted')
print(f"\nROC AUC Score: {roc_auc:.2f}")

# Plot ROC Curve for each class
plt.figure(figsize=(10, 6))
for class_idx in range(len(label_encoder1.classes_)):
    fpr, tpr, _ = roc_curve(y_test, voting_clf.predict_proba(X_test)[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{label_encoder1.classes_[class_idx]} (AUC = {roc_auc:.2f})')

plt.plot([0, 1], [0, 1], color='gray', linestyle='--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve for each class')
plt.legend(loc='lower right')
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder
from imblearn.over_sampling import SMOTE
from sklearn.impute import SimpleImputer

# Step 1: Load the data for each signal
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# Step 2: Preprocess the data for each signal (similar preprocessing for all signals)
def preprocess_data(df):
    # Replace missing numerical values with the mean (SimpleImputer)
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')  # You can change 'mean' to 'median' or 'most_frequent' if needed
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    # Encode the 'Sleep Stage' labels into numerical values
    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    # Separate the features and target
    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    # Handle class imbalance using SMOTE
    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess data for each signal
X1, y1, label_encoder1 = preprocess_data(df1)
X2, y2, label_encoder2 = preprocess_data(df2)
X3, y3, label_encoder3 = preprocess_data(df3)

# Step 3: Combine all signals' features into one feature set (X_combined)
X_combined = pd.concat([X1, X2, X3], axis=1)  # Concatenate along columns (features)

# Step 4: Split the combined data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_combined, y1, test_size=0.2, random_state=42, stratify=y1)

# Step 5: Initialize the models for each signal (using XGBoost, RandomForest, and GradientBoosting as base models)
model1 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=10,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model2 = XGBClassifier(
    n_estimators=450,  # Number of trees
    learning_rate=0.25,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
model3 = XGBClassifier(
    n_estimators=400,  # Number of trees
    learning_rate=0.2,  # Step size shrinkage
    max_depth=12,  # Maximum depth of a tree
    random_state=42,  # Random seed for reproducibility
    use_label_encoder=False,  # Disable the label encoder warning
    colsample_bytree=0.8,  # Fraction of features to consider per tree
    subsample=0.8,  # Fraction of samples to use for each tree
    eval_metric='mlogloss'  # Evaluation metric to use during training (for multi-class classification)
)
# Step 6: Create the VotingClassifier for final classification
voting_clf = VotingClassifier(estimators=[
    ('xgb', model1),
    ('gb', model2),
    ('rf', model3)
], voting='soft')  # Use 'soft' voting for probability-based classification

# Train the voting classifier on the combined dataset
voting_clf.fit(X_train, y_train)

# Step 7: Evaluate the performance of the voting classifier
y_pred = voting_clf.predict(X_test)

# Print the classification report
print("Classification Report for Voting Classifier (on Combined Signal Features):")
print(classification_report(y_test, y_pred, target_names=label_encoder1.classes_))

# Calculate accuracy
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from xgboost import XGBClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt

# =====================
# Step 1: Load 3 signal datasets
# =====================
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
df3 = pd.read_csv(file_path3)

# =====================
# Step 2: Preprocessing Function
# =====================
def preprocess_data(df):
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess all three
X1, y1, le1 = preprocess_data(df1)
X2, y2, le2 = preprocess_data(df2)
X3, y3, le3 = preprocess_data(df3)

# Train-test split
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)
X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)

# =====================
# Step 3: Define Base Models (Level-1)
# =====================
model1 = XGBClassifier(
    n_estimators=400, learning_rate=0.2, max_depth=10, random_state=42,
    subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', use_label_encoder=False
)
model2 = XGBClassifier(
    n_estimators=450, learning_rate=0.25, max_depth=12, random_state=42,
    subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', use_label_encoder=False
)
model3 = XGBClassifier(
    n_estimators=400, learning_rate=0.2, max_depth=12, random_state=42,
    subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', use_label_encoder=False
)

# =====================
# Step 4: Stacking Ensemble (Level-2 Meta Learner)
# =====================
stacking_clf = StackingClassifier(
    estimators=[
        ('xgb_eeg', model1),
        ('xgb_eog', model2),
        ('xgb_emg', model3)
    ],
    final_estimator=LogisticRegression(max_iter=1000, random_state=42),
    stack_method='predict_proba',  # Use probabilities as meta-features
    passthrough=True,              # Include original features too
    n_jobs=-1
)

# Train stacking model on one consistent dataset (EEG)
stacking_clf.fit(X_train1, y_train1)

# =====================
# Step 5: Evaluate
# =====================
y_pred = stacking_clf.predict(X_test1)
y_pred_proba = stacking_clf.predict_proba(X_test1)

print("Classification Report (Stacking Ensemble on EEG):")
print(classification_report(y_test1, y_pred, target_names=le1.classes_))

accuracy = accuracy_score(y_test1, y_pred)
print(f"Test Accuracy: {accuracy*100:.2f}%")

# Confusion matrix
cm = confusion_matrix(y_test1, y_pred)
print("\nConfusion Matrix:")
print(cm)

# =====================
# Step 6: Per-class Metrics
# =====================
class_metrics = {}
for class_idx in range(len(le1.classes_)):
    class_name = le1.classes_[class_idx]
    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    precision = precision_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# =====================
# Step 7: ROC Curve
# =====================
roc_auc = roc_auc_score(y_test1, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC: {roc_auc:.2f}")

plt.figure(figsize=(10,6))
for class_idx in range(len(le1.classes_)):
    fpr, tpr, _ = roc_curve(y_test1, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{le1.classes_[class_idx]}')
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Each Class (Stacking Ensemble)')
plt.legend()
plt.show()

# =====================
# Step 4: Stacking Ensemble (Level-2 Meta Learner)
# =====================
stacking_clf = StackingClassifier(
    estimators=[
        ('xgb_eeg', model1),
        ('xgb_eog', model2),
        ('xgb_emg', model3)
    ],
    final_estimator=LogisticRegression(max_iter=200, random_state=42),
    stack_method='predict_proba',  # Use probabilities as meta-features
    passthrough=True,              # Include original features too
    n_jobs=-1
)

# Train stacking model on one consistent dataset (EEG)
stacking_clf.fit(X_train1, y_train1)

# =====================
# Step 5: Evaluate
# =====================
y_pred = stacking_clf.predict(X_test1)
y_pred_proba = stacking_clf.predict_proba(X_test1)

print("Classification Report (Stacking Ensemble on EEG):")
print(classification_report(y_test1, y_pred, target_names=le1.classes_))

accuracy = accuracy_score(y_test1, y_pred)
print(f"Test Accuracy: {accuracy*100:.2f}%")

# Confusion matrix
cm = confusion_matrix(y_test1, y_pred)
print("\nConfusion Matrix:")
print(cm)

# =====================
# Step 6: Per-class Metrics
# =====================
class_metrics = {}
for class_idx in range(len(le1.classes_)):
    class_name = le1.classes_[class_idx]
    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    precision = precision_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# =====================
# Step 7: ROC Curve
# =====================
roc_auc = roc_auc_score(y_test1, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC: {roc_auc:.2f}")

plt.figure(figsize=(10,6))
for class_idx in range(len(le1.classes_)):
    fpr, tpr, _ = roc_curve(y_test1, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{le1.classes_[class_idx]}')
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Each Class (Stacking Ensemble)')
plt.legend()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.impute import SimpleImputer
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve
from xgboost import XGBClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt

# =====================
# Step 1: Load 3 signal datasets
# =====================
file_path1 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages.csv'
file_path2 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_eog_features.csv'
#file_path3 = '/content/drive/My Drive/Colab Notebooks/Sleepstage/extracted_features/merged_with_sleep_stages_emg_features.csv'

df1 = pd.read_csv(file_path1)
df2 = pd.read_csv(file_path2)
#df3 = pd.read_csv(file_path3)

# =====================
# Step 2: Preprocessing Function
# =====================
def preprocess_data(df):
    numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns
    imputer = SimpleImputer(strategy='mean')
    df[numerical_columns] = imputer.fit_transform(df[numerical_columns])

    label_encoder = LabelEncoder()
    df['Sleep Stage'] = label_encoder.fit_transform(df['Sleep Stage'])

    X = df.drop(columns=['Record', 'Segment Number', 'Sleep Stage'])
    y = df['Sleep Stage']

    smote = SMOTE(random_state=42)
    X_res, y_res = smote.fit_resample(X, y)

    return X_res, y_res, label_encoder

# Preprocess all three
X1, y1, le1 = preprocess_data(df1)
X2, y2, le2 = preprocess_data(df2)
#X3, y3, le3 = preprocess_data(df3)

# Train-test split
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)
X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)
#X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42, stratify=y3)

# =====================
# Step 3: Define Base Models (Level-1)
# =====================
model1 = XGBClassifier(
    n_estimators=400, learning_rate=0.2, max_depth=10, random_state=42,
    subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', use_label_encoder=False
)
model2 = XGBClassifier(
    n_estimators=450, learning_rate=0.25, max_depth=12, random_state=42,
    subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', use_label_encoder=False
)
model3 = XGBClassifier(
    n_estimators=400, learning_rate=0.2, max_depth=12, random_state=42,
    subsample=0.8, colsample_bytree=0.8, eval_metric='mlogloss', use_label_encoder=False
)

# =====================
# Step 4: Stacking Ensemble (Level-2 Meta Learner)
# =====================
stacking_clf = StackingClassifier(
    estimators=[
        ('xgb_eeg', model1),
        ('xgb_eog', model2)
    ],
    final_estimator=LogisticRegression(max_iter=1000, random_state=42),
    stack_method='predict_proba',  # Use probabilities as meta-features
    passthrough=True,              # Include original features too
    n_jobs=-1
)

# Train stacking model on one consistent dataset (EEG)
stacking_clf.fit(X_train1, y_train1)

# =====================
# Step 5: Evaluate
# =====================
y_pred = stacking_clf.predict(X_test1)
y_pred_proba = stacking_clf.predict_proba(X_test1)

print("Classification Report (Stacking Ensemble on EEG):")
print(classification_report(y_test1, y_pred, target_names=le1.classes_))

accuracy = accuracy_score(y_test1, y_pred)
print(f"Test Accuracy: {accuracy*100:.2f}%")

# Confusion matrix
cm = confusion_matrix(y_test1, y_pred)
print("\nConfusion Matrix:")
print(cm)

# =====================
# Step 6: Per-class Metrics
# =====================
class_metrics = {}
for class_idx in range(len(le1.classes_)):
    class_name = le1.classes_[class_idx]
    tp = cm[class_idx, class_idx]
    fn = cm[class_idx, :].sum() - tp
    tn = cm.sum() - (cm[class_idx, :].sum() + cm[:, class_idx].sum() - tp)
    fp = cm[:, class_idx].sum() - tp

    precision = precision_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    recall = recall_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    f1 = f1_score(y_test1, y_pred, average=None, labels=[class_idx])[0]
    sensitivity = tp / (tp + fn)
    specificity = tn / (tn + fp)

    class_metrics[class_name] = {
        'Precision': precision,
        'Recall (Sensitivity)': recall,
        'F1 Score': f1,
        'Sensitivity': sensitivity,
        'Specificity': specificity
    }

for class_name, metrics in class_metrics.items():
    print(f"\nMetrics for {class_name}:")
    for metric, value in metrics.items():
        print(f"{metric}: {value:.2f}")

# =====================
# Step 7: ROC Curve
# =====================
roc_auc = roc_auc_score(y_test1, y_pred_proba, multi_class='ovr', average='weighted')
print(f"\nWeighted ROC AUC: {roc_auc:.2f}")

plt.figure(figsize=(10,6))
for class_idx in range(len(le1.classes_)):
    fpr, tpr, _ = roc_curve(y_test1, y_pred_proba[:, class_idx], pos_label=class_idx)
    plt.plot(fpr, tpr, label=f'{le1.classes_[class_idx]}')
plt.plot([0,1],[0,1],'--',color='gray')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curves for Each Class (Stacking Ensemble)')
plt.legend()
plt.show()